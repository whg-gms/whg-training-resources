<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-statistical_modelling/introduction/bayes">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.20">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><title data-rh="true">The most important formula in science | The WHG training resources</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://well.ox.ac.uk//whg-training-resources/statistical_modelling/introduction/bayes/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="The most important formula in science | The WHG training resources"><meta data-rh="true" name="description" content="The most important formula is... Bayes theorem!"><meta data-rh="true" property="og:description" content="The most important formula is... Bayes theorem!"><link data-rh="true" rel="icon" href="/whg-training-resources/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://well.ox.ac.uk//whg-training-resources/statistical_modelling/introduction/bayes/"><link data-rh="true" rel="alternate" href="https://well.ox.ac.uk//whg-training-resources/statistical_modelling/introduction/bayes/" hreflang="en"><link data-rh="true" rel="alternate" href="https://well.ox.ac.uk//whg-training-resources/statistical_modelling/introduction/bayes/" hreflang="x-default"><link rel="stylesheet" href="/whg-training-resources/assets/css/styles.f24e0b7d.css">
<link rel="preload" href="/whg-training-resources/assets/js/runtime~main.8fe67747.js" as="script">
<link rel="preload" href="/whg-training-resources/assets/js/main.91c67f1f.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/whg-training-resources/"><div class="navbar__logo"><img src="/whg-training-resources/img/wchg.png" alt="My Site Logo" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/whg-training-resources/img/wchg-white.png" alt="My Site Logo" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title text--truncate">Training Resources</b></a><a class="navbar__item navbar__link" href="/whg-training-resources/overview/">Tutorials home</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/whg-training/whg-training-resources" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_S7eR colorModeToggle_vKtC"><button class="clean-btn toggleButton_rCf9 toggleButtonDisabled_Pu9x" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_v35p"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_nQuB"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_dLyj"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docsWrapper_mKqt"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_RiI4" type="button"></button><div class="docPage_ualW"><aside class="theme-doc-sidebar-container docSidebarContainer_UQUJ"><div class="sidebar_RiAD"><nav class="menu thin-scrollbar menu_izAj"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/whg-training-resources/statistical_modelling/introduction/">Introduction to statistics for genomics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Introduction to statistics for genomics&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/whg-training-resources/statistical_modelling/introduction/diagram/">Where statistics fits in</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/whg-training-resources/statistical_modelling/introduction/reasoning/">Statistics is reasoning with uncertainty</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/whg-training-resources/statistical_modelling/introduction/some_distributions/">Probability distributions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/whg-training-resources/statistical_modelling/introduction/bayes/">The most important formula in science</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/whg-training-resources/statistical_modelling/introduction/covid/">What to make of a COVID test</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/whg-training-resources/statistical_modelling/introduction/allele_frequencies/">Estimating allele frequencies</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/whg-training-resources/statistical_modelling/probability_cheatsheet/">Probability cheatsheet</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/whg-training-resources/statistical_modelling/regression_modelling/">Statistical modelling I - regression</a><button aria-label="Toggle the collapsible sidebar category &#x27;Statistical modelling I - regression&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/whg-training-resources/statistical_modelling/">Statistical modelling</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/whg-training-resources/statistical_modelling/Hidden_markov_models/">Glycophorin CNV calling tutorial</a><button aria-label="Toggle the collapsible sidebar category &#x27;Glycophorin CNV calling tutorial&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/whg-training-resources/statistical_modelling/notes/computing_pvalues/">notes</a></div></li></ul></nav></div></aside><main class="docMainContainer_uL0j"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_DM6M"><div class="docItemContainer_vinB"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Xlws" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/whg-training-resources/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_kU5B"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/whg-training-resources/statistical_modelling/introduction/"><span itemprop="name">Introduction to statistics for genomics</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">The most important formula in science</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_bZGK theme-doc-toc-mobile tocMobile_TmEX"><button type="button" class="clean-btn tocCollapsibleButton_l22C">On this page</button></div><div class="theme-doc-markdown markdown"><h1>The most important formula in science</h1><p>The most important formula is... Bayes theorem!</p><p>Let&#x27;s write it now. Suppose <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">Z</span></span></span></span></span> is <em>something we care about</em> - say, a scientific theory, or the chance of having disease.
We collect some data to tell us about it. Bayes&#x27; theorem now tells us:</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mrow><mo fence="true">(</mo><mi>Z</mi><mi mathvariant="normal">∣</mi><mtext>data</mtext><mo fence="true">)</mo></mrow><mo>=</mo><mfrac><mrow><mi>P</mi><mrow><mo fence="true">(</mo><mtext>data</mtext><mi mathvariant="normal">∣</mi><mi>Z</mi><mo fence="true">)</mo></mrow><mo>⋅</mo><mi>P</mi><mo stretchy="false">(</mo><mi>Z</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mtext>data</mtext><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P\left(Z|\text{data}\right) = \frac{P\left(\text{data}|Z\right) \cdot P(Z)}{P(\text{data})}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em">(</span><span class="mord mathnormal" style="margin-right:0.07153em">Z</span><span class="mord">∣</span><span class="mord text"><span class="mord">data</span></span><span class="mclose delimcenter" style="top:0em">)</span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord text"><span class="mord">data</span></span><span class="mclose">)</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em">(</span><span class="mord text"><span class="mord">data</span></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07153em">Z</span><span class="mclose delimcenter" style="top:0em">)</span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em">Z</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div><p>This formula lets us make inferences about the thing we care about (on the left) in terms of a <em>model of the data</em> (the
first term on the right).  </p><p>To make sense of this formula you need to understand the different pieces.  They have specific names.</p><ul><li><p><strong>The posterior</strong>. The left-hand side is what we should believe about the <em>thing we care about</em> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">Z</span></span></span></span></span>, once we have seen
the data, and is known as the posterior distribution.</p></li><li><p><strong>The prior</strong>. The second term on the right is an what we believed about the <em>thing we care about</em> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">Z</span></span></span></span></span>, <strong>before</strong> we saw
any data.  It is known as the prior distribution.</p></li><li><p><strong>The likelihood</strong>. The first term on the right is an assumed <strong>model for the data</strong>.
It is known as the <strong>likelihood</strong>.</p></li><li><p><strong>The normalising constant</strong>.  The denominator is discussed further below.</p></li></ul><p>In other words, Bayes&#x27; theorem tells us how to update our beliefs about something given some data.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="using-bayes-in-practice">Using Bayes in practice<a class="hash-link" href="#using-bayes-in-practice" title="Direct link to heading">​</a></h2><p>In practice it&#x27;s easy to use Bayes.  We do this:</p><ol><li>generate some data</li><li>define a model of the data (a likelihood function)</li><li>Figure out what prior information we have</li><li>And then apply the formula</li></ol><div class="admonition admonition-caution alert alert--warning"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>Warning</h5></div><div class="admonition-content"><p>Bayes theorem is a computational tool that depends on the modelled assumptions.  As long as we believe our data model
and prior information, it lets us quantify what our conclusions should be. It does not by itself answer more general
questions like &quot;how do I know if this model is sensible?&quot; or &quot;was there a data artifact?&quot; or &quot;What other possibilities
were there?&quot; - it&#x27;s purely a computational tool given the model at hand.</p></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="the-denominator">The denominator<a class="hash-link" href="#the-denominator" title="Direct link to heading">​</a></h2><p>You might be thinking - what&#x27;s that denominator, why is it a &#x27;normalising constant&#x27; - and how would you compute it?</p><p>Here are a few things to note.</p><ol><li><strong>The denominator does not depend on <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">Z</span></span></span></span></span></strong>.  (Look, there&#x27;s no <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">Z</span></span></span></span></span> in the brackets). </li></ol><p>In this sense it is a &#x27;constant&#x27;.</p><ol start="2"><li><strong>The denominator makes the left-hand side sum to one</strong> - because, after all, the left hand side is a distribution,
so it must sum to one.  This has two useful consequences.  First, in many cases we don&#x27;t have to worry about the
denominator at all - the maths already tells us what it is.  (We&#x27;ll do some examples like this shortly).  Second,
even if that doesn&#x27;t work out, we can compute the denominator by summing the numerator - over all the possible outcomes
instead of just the one we cared about, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">Z</span></span></span></span></span>.  In this form the equation becomes</li></ol><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>denominator</mtext><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mtext>data</mtext><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mi>Y</mi></munder><mi>P</mi><mrow><mo fence="true">(</mo><mtext>data</mtext><mi mathvariant="normal">∣</mi><mi>Y</mi><mo fence="true">)</mo></mrow><mo>⋅</mo><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{denominator} = P(\text{data}) = \sum_Y P\left(\text{data}|Y\right) \cdot P(Y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord text"><span class="mord">denominator</span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord text"><span class="mord">data</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.3443em;vertical-align:-1.2943em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.8557em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em">Y</span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2943em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em">(</span><span class="mord text"><span class="mord">data</span></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span><span class="mclose delimcenter" style="top:0em">)</span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span><span class="mclose">)</span></span></span></span></span></div><p>Second, </p><p>The second thing to note is that <strong>in many cases we don&#x27;t need to worry about the denominator at all</strong>.  Because:</p><ul><li>The left-hand side is a distribution - it <strong>sums to one</strong>.</li><li>So the normalising constant is just a number needed to <strong>make the thing sum to one</strong>.</li></ul><p>We&#x27;ll do some examples like this in a moment, in which everything works out analytically, and the mathematics tells us
what the normalising constant must be.</p><p>On the other hand there are situations where this doesn&#x27;t work - these are indeed harder.  In these situations,
computing the normalising constant is what methods like MCMC are for (but we won&#x27;t do that for now.)</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/whg-training/whg-training-resources/edit/main/docs/statistical_modelling/introduction/bayes.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_dcUD" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_foO9"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/whg-training-resources/statistical_modelling/introduction/some_distributions/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Probability distributions</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/whg-training-resources/statistical_modelling/introduction/covid/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">What to make of a COVID test</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_cNA8 thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#using-bayes-in-practice" class="table-of-contents__link toc-highlight">Using Bayes in practice</a></li><li><a href="#the-denominator" class="table-of-contents__link toc-highlight">The denominator</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">License</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/whg-training-resources/LICENSE/">License</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/whg-training/whg-training-resources" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 University of Oxford.  Built with Docusaurus.</div></div></div></footer></div>
<script src="/whg-training-resources/assets/js/runtime~main.8fe67747.js"></script>
<script src="/whg-training-resources/assets/js/main.91c67f1f.js"></script>
</body>
</html>