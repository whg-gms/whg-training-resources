"use strict";(self.webpackChunkwhg_training_resources=self.webpackChunkwhg_training_resources||[]).push([[5705],{3905:(e,t,a)=>{a.d(t,{Zo:()=>m,kt:()=>h});var n=a(7294);function s(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){s(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,s=function(e,t){if(null==e)return{};var a,n,s={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(s[a]=e[a]);return s}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(s[a]=e[a])}return s}var l=n.createContext({}),p=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},m=function(e){var t=p(e.components);return n.createElement(l.Provider,{value:t},e.children)},d="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,s=e.mdxType,i=e.originalType,l=e.parentName,m=o(e,["components","mdxType","originalType","parentName"]),d=p(a),u=s,h=d["".concat(l,".").concat(u)]||d[u]||c[u]||i;return a?n.createElement(h,r(r({ref:t},m),{},{components:a})):n.createElement(h,r({ref:t},m))}));function h(e,t){var a=arguments,s=t&&t.mdxType;if("string"==typeof e||s){var i=a.length,r=new Array(i);r[0]=u;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o[d]="string"==typeof e?e:s,r[1]=o;for(var p=2;p<i;p++)r[p]=a[p];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},4330:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>c,frontMatter:()=>i,metadata:()=>o,toc:()=>p});var n=a(7462),s=(a(7294),a(3905));const i={sidebar_position:1},r="Meta-analysis and fine-mapping practical",o={unversionedId:"genome_wide_association_studies/meta-analysis_and_fine-mapping/Introduction",id:"genome_wide_association_studies/meta-analysis_and_fine-mapping/Introduction",title:"Meta-analysis and fine-mapping practical",description:"Up to the table of contents / Forward to the meta-analysis section",source:"@site/docs/genome_wide_association_studies/meta-analysis_and_fine-mapping/Introduction.md",sourceDirName:"genome_wide_association_studies/meta-analysis_and_fine-mapping",slug:"/genome_wide_association_studies/meta-analysis_and_fine-mapping/Introduction",permalink:"/whg-training-resources/genome_wide_association_studies/meta-analysis_and_fine-mapping/Introduction",draft:!1,editUrl:"https://github.com/whg-training/whg-training-resources/edit/main/docs/genome_wide_association_studies/meta-analysis_and_fine-mapping/Introduction.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"sidebar8",previous:{title:"Meta-analysis and fine-mapping tutorial",permalink:"/whg-training-resources/genome_wide_association_studies/meta-analysis_and_fine-mapping/"},next:{title:"Meta-analysing two studies.",permalink:"/whg-training-resources/genome_wide_association_studies/meta-analysis_and_fine-mapping/Meta-analysis"}},l={},p=[{value:"Getting the data",id:"getting-the-data",level:3}],m={toc:p},d="wrapper";function c(e){let{components:t,...a}=e;return(0,s.kt)(d,(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,s.kt)("h1",{id:"meta-analysis-and-fine-mapping-practical"},"Meta-analysis and fine-mapping practical"),(0,s.kt)("p",null,(0,s.kt)("a",{parentName:"p",href:"/whg-training-resources/genome_wide_association_studies/meta-analysis_and_fine-mapping/"},"Up to the table of contents")," / ",(0,s.kt)("a",{parentName:"p",href:"/whg-training-resources/genome_wide_association_studies/meta-analysis_and_fine-mapping/Meta-analysis"},"Forward to the meta-analysis section")),(0,s.kt)("p",null,"So you've run your GWAS and you've found some signals.  Now what?"),(0,s.kt)("p",null,"In this practical we will implement two steps that both try to help narrow down association signals to the possible causal\nvariants. In the first of these, we will take data from two studies and ",(0,s.kt)("em",{parentName:"p"},"meta-analyse")," it to combined the evidence. Then, we\nwill use a fine-mapping method to try to identify a variant or variants that have the most evidence."),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"Note"),". Why can't we just use the P-values from the study directly, and pick the smallest? Well maybe that would work, but\nthere are two reasons to try something else:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"There might be more than one causal variant."),(0,s.kt)("li",{parentName:"ul"},"The P-values reflect a mixture of ",(0,s.kt)("em",{parentName:"li"},"effect size")," and ",(0,s.kt)("em",{parentName:"li"},"allele frequency"),".  They might not be the best way to identify the underlying variants.")),(0,s.kt)("h3",{id:"getting-the-data"},"Getting the data"),(0,s.kt)("p",null,"The data for this practical is in two files, ",(0,s.kt)("inlineCode",{parentName:"p"},"study1.z")," and ",(0,s.kt)("inlineCode",{parentName:"p"},"study2.z"),".  Load them now and take a look:"),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"Note.")," I am using the ",(0,s.kt)("a",{parentName:"p",href:"https://www.tidyverse.org"},"tidyverse")," for these examples. If you don't have that or don't want to get\nit, you can use base R functions like ",(0,s.kt)("inlineCode",{parentName:"p"},"read.table()")," instead."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},'library(tidyverse)\nstudy1 = read_delim( "study1.z", delim = " " )\nstudy2 = read_delim( "study2.z", delim = " " )\n\n')),(0,s.kt)("p",null,"Look at the data using ",(0,s.kt)("inlineCode",{parentName:"p"},"head()")," or ",(0,s.kt)("inlineCode",{parentName:"p"},"View()"),"."),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"Question.")," What's in the data?  How many SNPs?"),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"Note.")," For the analysis to work, the files will need to have the same SNPs in the same order.  Check this now!  (For example, you could check that ",(0,s.kt)("inlineCode",{parentName:"p"},"length( which( study1$rsid != study2$rsid ) )")," is zero.)"),(0,s.kt)("p",null,"The data for each study consists of:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"the rsid, chromosome, position and alleles of each SNP"),(0,s.kt)("li",{parentName:"ul"},"the minor allele frequency (",(0,s.kt)("inlineCode",{parentName:"li"},"maf"),") of each SNP"),(0,s.kt)("li",{parentName:"ul"},"and the GWAS / regression summary statistics, i.e. the maximum likelihood estimate ",(0,s.kt)("span",{parentName:"li",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mi",{parentName:"mrow"},"\u03b2")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\beta")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.05278em"}},"\u03b2")))))," and its standard error ",(0,s.kt)("span",{parentName:"li",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mi",{parentName:"mrow"},"s")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"s")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.4306em"}}),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"s"))))),", for the association test of the SNP against the phenotype.")),(0,s.kt)("p",null,"The data is for a region of the genome (overing ",(0,s.kt)("em",{parentName:"p"},"FUT2"),") where an association has been found."),(0,s.kt)("p",null,"The data doesn't contain any P-values or Bayes factors. However, if you joined the regression\npractical earlier you will know how to compute them:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"  study1$P = pnorm( -abs(study1$beta), sd = study1$se ) * 2\n  study2$P = pnorm( -abs(study2$beta), sd = study2$se ) * 2\n")),(0,s.kt)("p",null,"and similarly for study2. The expression above computes the mass under the two tails with effect >= ",(0,s.kt)("em",{parentName:"p"},"\u03b2"),", of the gaussian\ndistribution with standard deviation = the standard error. I.e. it is a P-value using the effect size estimate as a test\nstatistic."),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"Note.")," We could also compute a Bayes factor. For example, suppose we believe in relatively small effects, so choose a\n",(0,s.kt)("em",{parentName:"p"},"N(0,0.2",(0,s.kt)("sup",null,"2"),")")," prior. The calculation is:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"compute.bf <- function( beta, se, prior.variance ) {\n  (\n    pnorm( beta, mean = 0, sd = sqrt( se^2 + prior.variance ) )\n    /\n    pnorm( beta, mean = 0, sd = se )\n  )\n}\n\nstudy1$log10_BF = log10( compute.bf( study1$beta, study1$se , prior.variance = 0.2 ))\nstudy2$log10_BF = log10( compute.bf( study2$beta, study2$se , prior.variance = 0.2 ))\n")),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"Question.")," How much evidence is there in the two studies? Are any of the most-associated SNPs\nshared between the two studies?"),(0,s.kt)("p",null,"When you're ready, ",(0,s.kt)("a",{parentName:"p",href:"/whg-training-resources/genome_wide_association_studies/meta-analysis_and_fine-mapping/Meta-analysis"},"start meta-analysing"),"."))}c.isMDXComponent=!0}}]);