"use strict";(self.webpackChunkwhg_training_resources=self.webpackChunkwhg_training_resources||[]).push([[4265],{3905:(a,e,t)=>{t.d(e,{Zo:()=>o,kt:()=>k});var s=t(7294);function n(a,e,t){return e in a?Object.defineProperty(a,e,{value:t,enumerable:!0,configurable:!0,writable:!0}):a[e]=t,a}function m(a,e){var t=Object.keys(a);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(a);e&&(s=s.filter((function(e){return Object.getOwnPropertyDescriptor(a,e).enumerable}))),t.push.apply(t,s)}return t}function p(a){for(var e=1;e<arguments.length;e++){var t=null!=arguments[e]?arguments[e]:{};e%2?m(Object(t),!0).forEach((function(e){n(a,e,t[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(a,Object.getOwnPropertyDescriptors(t)):m(Object(t)).forEach((function(e){Object.defineProperty(a,e,Object.getOwnPropertyDescriptor(t,e))}))}return a}function r(a,e){if(null==a)return{};var t,s,n=function(a,e){if(null==a)return{};var t,s,n={},m=Object.keys(a);for(s=0;s<m.length;s++)t=m[s],e.indexOf(t)>=0||(n[t]=a[t]);return n}(a,e);if(Object.getOwnPropertySymbols){var m=Object.getOwnPropertySymbols(a);for(s=0;s<m.length;s++)t=m[s],e.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(a,t)&&(n[t]=a[t])}return n}var i=s.createContext({}),l=function(a){var e=s.useContext(i),t=e;return a&&(t="function"==typeof a?a(e):p(p({},e),a)),t},o=function(a){var e=l(a.components);return s.createElement(i.Provider,{value:e},a.children)},c="mdxType",N={inlineCode:"code",wrapper:function(a){var e=a.children;return s.createElement(s.Fragment,{},e)}},h=s.forwardRef((function(a,e){var t=a.components,n=a.mdxType,m=a.originalType,i=a.parentName,o=r(a,["components","mdxType","originalType","parentName"]),c=l(t),h=n,k=c["".concat(i,".").concat(h)]||c[h]||N[h]||m;return t?s.createElement(k,p(p({ref:e},o),{},{components:t})):s.createElement(k,p({ref:e},o))}));function k(a,e){var t=arguments,n=e&&e.mdxType;if("string"==typeof a||n){var m=t.length,p=new Array(m);p[0]=h;var r={};for(var i in e)hasOwnProperty.call(e,i)&&(r[i]=e[i]);r.originalType=a,r[c]="string"==typeof a?a:n,p[1]=r;for(var l=2;l<m;l++)p[l]=t[l];return s.createElement.apply(null,p)}return s.createElement.apply(null,t)}h.displayName="MDXCreateElement"},9721:(a,e,t)=>{t.r(e),t.d(e,{assets:()=>i,contentTitle:()=>p,default:()=>N,frontMatter:()=>m,metadata:()=>r,toc:()=>l});var s=t(7462),n=(t(7294),t(3905));const m={},p="Asymptotics and  P-values",r={unversionedId:"statistical_modelling/notes/computing_pvalues",id:"statistical_modelling/notes/computing_pvalues",title:"Asymptotics and  P-values",description:"Much of classical statistics relies on 'asymptotics', which means statistical behaviour when data",source:"@site/docs/statistical_modelling/notes/computing_pvalues.md",sourceDirName:"statistical_modelling/notes",slug:"/statistical_modelling/notes/computing_pvalues",permalink:"/whg-training-resources/statistical_modelling/notes/computing_pvalues",draft:!1,editUrl:"https://github.com/whg-training/whg-training-resources/edit/main/docs/statistical_modelling/notes/computing_pvalues.md",tags:[],version:"current",frontMatter:{},sidebar:"sidebar6",previous:{title:"Modelling CNVs using a Hidden Markov Model",permalink:"/whg-training-resources/statistical_modelling/Hidden_markov_models/glycophorin_cnv_hmm"}},i={},l=[{value:"Asymptotics in practice",id:"asymptotics-in-practice",level:2},{value:"The likelihood ratio test",id:"the-likelihood-ratio-test",level:2}],o={toc:l},c="wrapper";function N(a){let{components:e,...t}=a;return(0,n.kt)(c,(0,s.Z)({},o,t,{components:e,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"asymptotics-and--p-values"},"Asymptotics and  P-values"),(0,n.kt)("p",null,"Much of classical statistics relies on 'asymptotics', which means statistical behaviour when data\nvolumes get large. In this setting likelihood functions tend to become very well-behaved - they\nbecome governed by Gaussian distributions."),(0,n.kt)("p",null,"There are two closely related ways this plays out:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"If \u03b2\u2080 is the 'true' value of the parameter \u03b2, then the maximum likelihood estimate \u03b2\u0302 becomes asymptotically normally distributed around \u03b2\u2080."),(0,n.kt)("li",{parentName:"ul"},"the likelihood function itself becomes approximately guassian (i.e. the log-liklihood becomes quadratic)")),(0,n.kt)("p",null,"What's more, the variance in each case asymptotically the same - it is approximately equal to ",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mi",{parentName:"mrow"},"I"),(0,n.kt)("mo",{parentName:"mrow"},"="),(0,n.kt)("mo",{parentName:"mrow"},"\u2212"),(0,n.kt)("msup",{parentName:"mrow"},(0,n.kt)("mi",{parentName:"msup"},"H"),(0,n.kt)("mrow",{parentName:"msup"},(0,n.kt)("mo",{parentName:"mrow"},"\u2212"),(0,n.kt)("mn",{parentName:"mrow"},"1")))),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"I = -H^{-1}")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6833em"}}),(0,n.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.07847em"}},"I"),(0,n.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}}),(0,n.kt)("span",{parentName:"span",className:"mrel"},"="),(0,n.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}})),(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8974em",verticalAlign:"-0.0833em"}}),(0,n.kt)("span",{parentName:"span",className:"mord"},"\u2212"),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.08125em"}},"H"),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.8141em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-3.063em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},"\u2212"),(0,n.kt)("span",{parentName:"span",className:"mord mtight"},"1")))))))))))))," where ",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mi",{parentName:"mrow"},"H")),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"H")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6833em"}}),(0,n.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.08125em"}},"H")))))," is the second derivative of the loglikelihood function."),(0,n.kt)("p",null,"For this to hold, some conditions must of course be true. Two crucial ones are: that not just the\ndata points but the 'amount of information' in the data ",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mo",{parentName:"mrow"},"\u2192"),(0,n.kt)("mi",{parentName:"mrow",mathvariant:"normal"},"\u221e")),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\rightarrow \\infty")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.3669em"}}),(0,n.kt)("span",{parentName:"span",className:"mrel"},"\u2192"),(0,n.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}})),(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.4306em"}}),(0,n.kt)("span",{parentName:"span",className:"mord"},"\u221e")))))," (i.e. it's no use\nhaving a million measurements of the same thing). Also, for it to work the true parameter value\nmust be in the interior of parameter space, the likelihood function has to be sufficiently smooth,\nand so on."),(0,n.kt)("p",null,"For more on the asymptotics of the mle see ",(0,n.kt)("a",{parentName:"p",href:"https://web.stanford.edu/~hastie/CASI_files/PDF/casi.pdf"},"Efron & Hastie")," Chapter 4."),(0,n.kt)("h2",{id:"asymptotics-in-practice"},"Asymptotics in practice"),(0,n.kt)("p",null,"Asymptotics are everywhere. For example, consider this logistic regression fit done in ",(0,n.kt)("inlineCode",{parentName:"p"},"R"),":"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-R"},'X = # (some data)\nfit = glm(\n    outcome ~ predictor + covariate1 + covariate2,\n    family="binomial",\n    data = X\n)\n\nprint( summary(fit)$coeff )\n')),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"               Estimate Std. Error    z value     Pr(>|z|)\n(Intercept)  0.02420081 0.02221072  1.0896003 2.758893e-01\npredictor    0.19235083 0.03311230  5.8090450 6.283019e-09\ncovariate1  -0.01183213 0.01636611 -0.7229654 4.697012e-01\ncovariate2   0.12801224 0.01666143  7.6831465 1.552279e-14\n")),(0,n.kt)("p",null,"In this output:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"The ",(0,n.kt)("inlineCode",{parentName:"p"},"Estimate")," column gives the maximum likelihood estimate ",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mover",{parentName:"mrow",accent:"true"},(0,n.kt)("mi",{parentName:"mover"},"\u03b2"),(0,n.kt)("mo",{parentName:"mover"},"^"))),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\hat{\\beta}")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"1.1523em",verticalAlign:"-0.1944em"}}),(0,n.kt)("span",{parentName:"span",className:"mord accent"},(0,n.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.9579em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-3em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"3em"}}),(0,n.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.05278em"}},"\u03b2")),(0,n.kt)("span",{parentName:"span",style:{top:"-3.2634em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"3em"}}),(0,n.kt)("span",{parentName:"span",className:"accent-body",style:{left:"-0.1667em"}},(0,n.kt)("span",{parentName:"span",className:"mord"},"^")))),(0,n.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.1944em"}},(0,n.kt)("span",{parentName:"span"})))))))))," - that is, the value\nmaximising the likelihood function. (This also maximises the log-likelihood, of course, because\n",(0,n.kt)("inlineCode",{parentName:"p"},"log")," is monotone increasing.)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"The ",(0,n.kt)("inlineCode",{parentName:"p"},"Std. Error")," is computed from the curvature of the log-likelihood function at the mode as\nfollows: let ",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mi",{parentName:"mrow"},"H")),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"H")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6833em"}}),(0,n.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.08125em"}},"H")))))," be the 2nd derivative at the mode, and compute ",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mi",{parentName:"mrow"},"I"),(0,n.kt)("mo",{parentName:"mrow"},"="),(0,n.kt)("mo",{parentName:"mrow"},"\u2212"),(0,n.kt)("msup",{parentName:"mrow"},(0,n.kt)("mi",{parentName:"msup"},"H"),(0,n.kt)("mrow",{parentName:"msup"},(0,n.kt)("mo",{parentName:"mrow"},"\u2212"),(0,n.kt)("mn",{parentName:"mrow"},"1")))),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"I=-H^{-1}")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6833em"}}),(0,n.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.07847em"}},"I"),(0,n.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}}),(0,n.kt)("span",{parentName:"span",className:"mrel"},"="),(0,n.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}})),(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8974em",verticalAlign:"-0.0833em"}}),(0,n.kt)("span",{parentName:"span",className:"mord"},"\u2212"),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.08125em"}},"H"),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.8141em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-3.063em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},"\u2212"),(0,n.kt)("span",{parentName:"span",className:"mord mtight"},"1"))))))))))))),". Then the standard\nerrors are square root of the diagonal entries.")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"The ",(0,n.kt)("inlineCode",{parentName:"p"},"Pr(>|z|)")," column gives 'Wald test' P-values and are computed as follows. Consider a Gaussian\ndistribution centred at 0 with standard deviation equal to the given standard error. Then compute\nthe mass under the two tails of this distribution."))),(0,n.kt)("p",null,"You can confirm this P-value computation yourself by manually computing the P-value:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-R"},"coefficients = summary(fit)$coeff\n\npvalue = 2 * pnorm(\n    -abs(coefficients['predictor', 'Estimate']),\n    mean = 0,\n    sd = coefficients['predictor', 'Std. Error']\n)\nprint(pvalue)\n")),(0,n.kt)("p",null,"An ",(0,n.kt)("strong",{parentName:"p"},"odd thing")," about this is that even though we are computing a P-value, which is all about the\n'null' model where ",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mi",{parentName:"mrow"},"\u03b2"),(0,n.kt)("mo",{parentName:"mrow"},"\u2261"),(0,n.kt)("mn",{parentName:"mrow"},"0")),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\beta \\equiv 0")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,n.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.05278em"}},"\u03b2"),(0,n.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}}),(0,n.kt)("span",{parentName:"span",className:"mrel"},"\u2261"),(0,n.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}})),(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6444em"}}),(0,n.kt)("span",{parentName:"span",className:"mord"},"0"))))),", to compute this p-value we have only fit the full model (where\n",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mi",{parentName:"mrow"},"\u03b2")),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\beta")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,n.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.05278em"}},"\u03b2")))))," can be nonzero)."),(0,n.kt)("p",null,"The Wald test is fairly ubiqitousin statistical genetics - for example it's what\n",(0,n.kt)("a",{parentName:"p",href:"https://www.cog-genomics.org/plink/"},"plink")," computes when conducting association tests."),(0,n.kt)("h2",{id:"the-likelihood-ratio-test"},"The likelihood ratio test"),(0,n.kt)("p",null,"The Wald test is not the only way to compute a p-value. Another very useful form is the ",(0,n.kt)("em",{parentName:"p"},"likelihood\nratio test"),". This is obtained by comparing the maximum log-likelihood under the null model and\nunder the full model via the formula:"),(0,n.kt)("div",{className:"math math-display"},(0,n.kt)("span",{parentName:"div",className:"katex-display"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mtext",{parentName:"mrow"},"lr\xa0ratio\xa0test\xa0statistic"),(0,n.kt)("mo",{parentName:"mrow"},"="),(0,n.kt)("mo",{parentName:"mrow"},"\u2212"),(0,n.kt)("mn",{parentName:"mrow"},"2"),(0,n.kt)("mo",{parentName:"mrow"},"\xd7"),(0,n.kt)("mrow",{parentName:"mrow"},(0,n.kt)("mo",{parentName:"mrow",fence:"true"},"("),(0,n.kt)("msub",{parentName:"mrow"},(0,n.kt)("mtext",{parentName:"msub"},"ll"),(0,n.kt)("mtext",{parentName:"msub"},"null")),(0,n.kt)("mo",{parentName:"mrow"},"\u2212"),(0,n.kt)("msub",{parentName:"mrow"},(0,n.kt)("mtext",{parentName:"msub"},"ll"),(0,n.kt)("mtext",{parentName:"msub"},"alternative")),(0,n.kt)("mo",{parentName:"mrow",fence:"true"},")"))),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\text{lr ratio test statistic} = -2 \\times \\left( \\text{ll}_{\\text{null}} - \\text{ll}_{\\text{alternative}} \\right)")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6944em"}}),(0,n.kt)("span",{parentName:"span",className:"mord text"},(0,n.kt)("span",{parentName:"span",className:"mord"},"lr\xa0ratio\xa0test\xa0statistic")),(0,n.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}}),(0,n.kt)("span",{parentName:"span",className:"mrel"},"="),(0,n.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}})),(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7278em",verticalAlign:"-0.0833em"}}),(0,n.kt)("span",{parentName:"span",className:"mord"},"\u2212"),(0,n.kt)("span",{parentName:"span",className:"mord"},"2"),(0,n.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,n.kt)("span",{parentName:"span",className:"mbin"},"\xd7"),(0,n.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}})),(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,n.kt)("span",{parentName:"span",className:"minner"},(0,n.kt)("span",{parentName:"span",className:"mopen delimcenter",style:{top:"0em"}},"("),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord text"},(0,n.kt)("span",{parentName:"span",className:"mord"},"ll")),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3361em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-2.55em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},(0,n.kt)("span",{parentName:"span",className:"mord text mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},"null")))))),(0,n.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,n.kt)("span",{parentName:"span"})))))),(0,n.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,n.kt)("span",{parentName:"span",className:"mbin"},"\u2212"),(0,n.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord text"},(0,n.kt)("span",{parentName:"span",className:"mord"},"ll")),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3361em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-2.55em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},(0,n.kt)("span",{parentName:"span",className:"mord text mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},"alternative")))))),(0,n.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,n.kt)("span",{parentName:"span"})))))),(0,n.kt)("span",{parentName:"span",className:"mclose delimcenter",style:{top:"0em"}},")"))))))),(0,n.kt)("p",null,"(It's a ",(0,n.kt)("em",{parentName:"p"},"likelihood ratio test")," because if you take the exponential of the above expression you get\nsomething proportional to the ratio of likelihoods. "),(0,n.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,n.kt)("div",{parentName:"div",className:"admonition-heading"},(0,n.kt)("h5",{parentName:"div"},(0,n.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,n.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,n.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,n.kt)("div",{parentName:"div",className:"admonition-content"},(0,n.kt)("p",{parentName:"div"},"The alternative model log-likelihood is always (at least) larger than under the null, even if the\nnull model is true. This is because the model has an extra parameter. Except in degenerate\nsituations it will be strictly larger because sampling variation will mean that the best fit to the\ndata won't be exactly at the true value ",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("msub",{parentName:"mrow"},(0,n.kt)("mi",{parentName:"msub"},"\u03b2"),(0,n.kt)("mn",{parentName:"msub"},"0"))),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\beta_0")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.05278em"}},"\u03b2"),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3011em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"-0.0528em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},"0")))),(0,n.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,n.kt)("span",{parentName:"span"})))))))))),"."))),(0,n.kt)("p",null,"If the asymptotic approximation above holds, then the likelihood ratio test statistic turns out to\nbe Chi-squared distributed, thus again easy to compute. "),(0,n.kt)("p",null,"In R, following the above example, we could compute it like this:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-R"},'null.fit = glm( outcome ~ covariate1 + covariate2, family="binomial", data = X )\nlr.statistic = -2 * ( logLik(fit) - logLik(null.fit))\npchisq( lr.statistic, df = 1 )\n')),(0,n.kt)("p",null,"A quicker way is to use the ",(0,n.kt)("inlineCode",{parentName:"p"},"drop1")," function:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-R"},'    drop1( fit, test = "LRT" )\n')),(0,n.kt)("p",null,"which will successively drop 1 variable out of the formulae and compute the LRT for it."))}N.isMDXComponent=!0}}]);