"use strict";(self.webpackChunkwhg_training_resources=self.webpackChunkwhg_training_resources||[]).push([[4214],{3905:(e,n,t)=>{t.d(n,{Zo:()=>m,kt:()=>h});var i=t(7294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);n&&(i=i.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,i)}return t}function r(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,i,a=function(e,n){if(null==e)return{};var t,i,a={},o=Object.keys(e);for(i=0;i<o.length;i++)t=o[i],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)t=o[i],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var l=i.createContext({}),p=function(e){var n=i.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):r(r({},n),e)),t},m=function(e){var n=p(e.components);return i.createElement(l.Provider,{value:n},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var n=e.children;return i.createElement(i.Fragment,{},n)}},d=i.forwardRef((function(e,n){var t=e.components,a=e.mdxType,o=e.originalType,l=e.parentName,m=s(e,["components","mdxType","originalType","parentName"]),c=p(t),d=a,h=c["".concat(l,".").concat(d)]||c[d]||u[d]||o;return t?i.createElement(h,r(r({ref:n},m),{},{components:t})):i.createElement(h,r({ref:n},m))}));function h(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var o=t.length,r=new Array(o);r[0]=d;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s[c]="string"==typeof e?e:a,r[1]=s;for(var p=2;p<o;p++)r[p]=t[p];return i.createElement.apply(null,r)}return i.createElement.apply(null,t)}d.displayName="MDXCreateElement"},2030:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>u,frontMatter:()=>o,metadata:()=>s,toc:()=>p});var i=t(7462),a=(t(7294),t(3905));const o={sidebar_position:2},r="Modelling CNVs using a Hidden Markov Model",s={unversionedId:"statistical_modelling/Hidden_markov_models/glycophorin_cnv_hmm",id:"statistical_modelling/Hidden_markov_models/glycophorin_cnv_hmm",title:"Modelling CNVs using a Hidden Markov Model",description:"!! Note !!  To run this part of the practical, you first need to have computed a set of log-likelihoods for",source:"@site/docs/statistical_modelling/Hidden_markov_models/glycophorin_cnv_hmm.md",sourceDirName:"statistical_modelling/Hidden_markov_models",slug:"/statistical_modelling/Hidden_markov_models/glycophorin_cnv_hmm",permalink:"/whg-training-resources/statistical_modelling/Hidden_markov_models/glycophorin_cnv_hmm",draft:!1,editUrl:"https://github.com/whg-training/whg-training-resources/edit/main/docs/statistical_modelling/Hidden_markov_models/glycophorin_cnv_hmm.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"sidebar6",previous:{title:"Warmup: examining read coverage in a region",permalink:"/whg-training-resources/statistical_modelling/Hidden_markov_models/glycophorin_cnv_warmup"},next:{title:"Asymptotics and  P-values",permalink:"/whg-training-resources/statistical_modelling/notes/computing_pvalues"}},l={},p=[{value:"The forward-backward algorithm",id:"the-forward-backward-algorithm",level:2},{value:"Computing transition probabilities",id:"computing-transition-probabilities",level:2},{value:"The Copy number HMM",id:"the-copy-number-hmm",level:2},{value:"Run the HMM",id:"run-the-hmm",level:2},{value:"Further directions",id:"further-directions",level:2}],m={toc:p},c="wrapper";function u(e){let{components:n,...t}=e;return(0,a.kt)(c,(0,i.Z)({},m,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"modelling-cnvs-using-a-hidden-markov-model"},"Modelling CNVs using a Hidden Markov Model"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"}," !! Note !! ")," To run this part of the practical, you first need to have computed a set of log-likelihoods for\neach sample at each site in the relevant dataset. The code to do this was explained in the\n",(0,a.kt)("a",{parentName:"p",href:"/whg-training-resources/statistical_modelling/Hidden_markov_models/glycophorin_cnv_warmup"},"warmup tutorial"),", which you can also find in this directory."),(0,a.kt)("p",null,"If you haven't run it in this R session, please run this now:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-R"},"    source( 'glycophorin_cnv_warmup_code.R' )\n")),(0,a.kt)("p",null,"You should now have the data (",(0,a.kt)("inlineCode",{parentName:"p"},"X"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"sites"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"samples"),") loaded, and you should have a 532 x 200 x 6 array called ",(0,a.kt)("inlineCode",{parentName:"p"},"copy.number.lls")," loaded.  Check by writing:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-R"},"    View( copy.number.lls )\n")),(0,a.kt)("p",null,"You should see a bunch of (mostly large and negative) numbers."),(0,a.kt)("h2",{id:"the-forward-backward-algorithm"},"The forward-backward algorithm"),(0,a.kt)("p",null,"The forward.backward() function implements (guess what?) the HMM forward-backward algorithm based on arrays of emission\nand transition probabilities, and the prior. First, the alpha and beta values (forward and backward algorithm\nprobabilities) are computed. Then, the two are combined to compute state probabilities (gamma) at each site."),(0,a.kt)("p",null,"These computations and notation are all as in the Rabiner HMM tutorial:\n",(0,a.kt)("a",{parentName:"p",href:"https://web.ece.ucsb.edu/Faculty/Rabiner/ece259/Reprints/tutorial%20on%20hmm%20and%20applications.pdf"},"https://web.ece.ucsb.edu/Faculty/Rabiner/ece259/Reprints/tutorial%20on%20hmm%20and%20applications.pdf")),(0,a.kt)("p",null,"The only complication is that to avoid numerical over/underflow we work in log space, so have to change expressions\naccordingly. Multiplications get converted to additions in log space.  But to avoid numerical issues, ",(0,a.kt)("em",{parentName:"p"},"additions")," of\nprobabilities are best converted by using the ",(0,a.kt)("inlineCode",{parentName:"p"},"log.sum.exp()")," function (that should already be loaded), rather than\nusing ",(0,a.kt)("inlineCode",{parentName:"p"},"log( sum( exp()))")," directly."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-R"},"# a generally useful function:\necho <- function( message, ... ) {\n    cat( sprintf( message, ... ))\n}\n\n\nforward.backward <- function(\n    emissions,              # matrix of emission log-probabilities (LxD)\n    transitions,       # (L-1)xDxD array of transition probabilities into each bin\n    prior                  # vector of prior state probabilities\n) {\n    # FORWARD ALGORITHM\n    forward = function( emissions, transitions, prior ) {\n        L = nrow(emissions)\n        D = ncol(transitions)\n        alpha = matrix( 0, nrow = L, ncol = D )\n    \n        # 1. Initialisation\n        # alpha_1 gets initialised from prior and observations multiplied.\n        # (Multiplied probabilities, but we are working in log space so add them)\n        alpha[1,] = emissions[1,] + prior\n\n        # alpha_n+1 is obtained by summing over states i at time n\n        # In non-log-space this would be:\n        #          ( sum_i alpha[n,i] * transitions[n,i,j] ) * emissions[n,j]\n        # But in log space it is instead:\n        #   alpha[n+1,j] = logsumexp_i(alpha[n,i] + transitions[n,i,j]) + emissions[n,j]\n        for( n in 1:(L-1)) {\n            for( j in 1:D ) {\n                alpha[n+1,j] = log.sum.exp( alpha[n,] + transitions[n,,j] ) + emissions[n+1,j]\n            }\n        }\n        return( alpha )\n    }\n\n    backward <- function( emissions, transitions ) {\n        L = nrow(emissions)\n        D = ncol(transitions)\n\n        beta = matrix( 0, nrow = L, ncol = D )\n    \n        # Initialisation, initialise to prob = 1 (or log prob = 0)\n        beta[L,] = 0\n    \n        # Usually\n        # beta_n is obtained by summing over states j at time n+1\n        #   sum_j transitions[n,i,j] * emissions[n+1,j] * beta[n+1,j]\n        # but in log space it is instead:\n        #   logsumexp_j( transitions[n,i,j] + emissions[n+1,j] + beta[n+1,j] )\n    \n        for( n in (L-1):1 ) {\n            for( i in 1:D ) {\n                beta[n,i] = log.sum.exp( transitions[n,i,] + emissions[n+1,] + beta[n+1,] )\n            }\n        }\n        return( beta )\n    }\n\n    L = nrow(emissions)\n    copy.numbers = 0:(length(prior)-1)\n\n    # Posterior state probabilities\n    alpha = forward( emissions, transitions, prior )\n    beta = backward( emissions, transitions )\n\n    # Posterior state probabilities\n    gamma = alpha + beta - log.sum.exp( alpha[L,] )\n    \n    return(\n        list(\n            emissions = emissions,\n            alpha = alpha,  # Forward log-probabilities\n            beta = beta,    # Backward log-probabilities\n            gamma = gamma # Marginal log-probabilities\n        )\n    ) ;\n\n    # Sanity checks:\n    # 1: rowSums( exp( gamma )) == 1, marginal probalities sum to one\n    # 2: rowSums( exp( alpha + beta )) should all be equal (total observation probability)\n}\n")),(0,a.kt)("h2",{id:"computing-transition-probabilities"},"Computing transition probabilities"),(0,a.kt)("p",null,"To define transition probabilities, we'll assume a model of exponential copy number tract length with expected length\ncontrolled by a rate parameter ",(0,a.kt)("inlineCode",{parentName:"p"},"lambda"),".  "),(0,a.kt)("p",null,"We also pass in a list of between-site distances, but in our example all bins are the same size, so we will just pass\nin a list of 1s and interpret parameters accordingly.  In other words, ",(0,a.kt)("inlineCode",{parentName:"p"},"lambda=1")," would correspond to an expected tract length of 1600bp."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-R"},"# compute.transitions() returns an array of transition log-probabilities\n# This is arranged so that, if tp is the result then\n# tp[n,i,j] is the log-probability of transitioning from state i to state j at position n\ncompute.transitions <- function(\n    distances,      # distance between points\n    lambda,         # 'switchiness'\n    prior           # prior state log-probabilities \n) {\n    # Given distance d, probability of switching\n    # to a new state is 1 - e^-lambda d\n    # (This starts at 0 when d = 0 and increases to 1 when d is large).\n    # If switching we pick a new state from the prior.\n    # (NB. this implies the chain is stationary.)\n    # We work in log space so convert expressions accordingly\n    D = length( prior )\n\n    result = array(\n        NA,\n        dim = c(\n            length( distances ),\n            D,\n            D\n        )\n    )\n    for( n in 1:length(distances)) {\n        distance = distances[n]\n        scaled.prior = prior + log( 1 - exp( -lambda * distance ))\n        result[n,,] = matrix(\n            rep( scaled.prior, D ),\n            byrow = T,\n            nrow = D,\n            ncol = D\n        )\n        # Probability of no switch is e^-lambda d\n        diag( result[n,,] ) = rep( -lambda * distance, D )\n    }\n    # Note: (exponentiated) rows now sum to one because prior sums to 1.\n    return( result )\n}\n")),(0,a.kt)("h2",{id:"the-copy-number-hmm"},"The Copy number HMM"),(0,a.kt)("p",null,"The next function puts this all together to implement the CNV-finding HMM.\nIt takes:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"a matrix of per-site, per-sample copy number logliklihoods to be used as emission probabilities."),(0,a.kt)("li",{parentName:"ul"},"prior probabilities for each copy number state"),(0,a.kt)("li",{parentName:"ul"},"and a lambda used to determine expected length of transition")),(0,a.kt)("p",null,"It also takes a last parameter (",(0,a.kt)("inlineCode",{parentName:"p"},"site.multipliers"),") that can used to control for per-site variation, but we're not using it here."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-R"},'# Function cnv.hmm()\n# Implement one iteration of the CNV-finding HMM for a matrix of N samples and L sites (bins)\n#\n# Return value is a list with several members\n# - `prior` is the copy number prior, as passed in\n# - `marginal.log.probabilities` are the the log-posterior probabilities of each copy number given the HMM (i.e. gamma in the HMM)\n# - `expected.copy.numbers` are the expected copy numbers at each site, given the posteriors.\n# - `emission.log.probabilities` the matrix of copy number lls, as passed in\n# The total log-probability across all samples (this is the total log-likelihood of our model)\ncnv.hmm <- function(\n    copy.number.lls,\n    prior,\n    lambda,\n    site.multipliers\n) {\n\n    # sanity checks\n    stopifnot( dim( copy.number.lls )[3] == length( prior ))\n\n    # Get a list of samples\n    samples = dimnames(copy.number.lls)[[2]]\n    N = length( samples )\n    L = nrow( copy.number.lls) # number of sites\n\n    echo( "Running HMM for %d samples at %d sites...\\n", N, L )\n    \n    # prior is assumed to be for copy number states 0 ... K\n    copy.numbers = 0:(length(prior)-1)\n    log.prior = log( prior )\n\n    result = list(\n        prior = prior,\n        # This array reports the posterior probability of each\n        # copy number state at each site for each sample\n        # under the HMM model\n        marginal.log.probabilities = array(\n            NA,\n            dim = c( N, L, length( copy.numbers )),\n            dimnames = list(\n                samples,\n                rownames( copy.number.lls ),\n                sprintf( "cn=%d", copy.numbers )\n            )\n        ),\n        expected.copy.numbers = array(\n            NA,\n            dim = c( L, N ),\n            dimnames = list(\n                rownames(copy.number.lls ),\n                samples\n            )\n        ),\n        emission.log.probabilities = copy.number.lls,\n        total.log.probability = 0\n    )\n    transitions = compute.transitions( rep( 1, L-1 ), lambda, log.prior )\n    for( i in 1:N ) {\n        emissions = copy.number.lls[,i,]\n        fb = forward.backward( emissions, transitions, log.prior )\n        result$total.log.probability = result$total.log.probability + log.sum.exp( fb$alpha[1,] + fb$beta[1,] )\n        result$marginal.log.probabilities[i,,] = fb$gamma\n        result$expected.copy.numbers[,i] = exp(fb$gamma) %*% copy.numbers\n        echo( "." )\n        if( i %% 50 == 0 ) {\n            echo( "\\n" )\n        }\n    }\n    echo( "\\nok\\n" )\n    return( result ) ;\n}\n')),(0,a.kt)("h2",{id:"run-the-hmm"},"Run the HMM"),(0,a.kt)("p",null,"Ok we are ready to run!  Let's set it going:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-R"},'result = cnv.hmm(\n    # Copy number log-likelihoods computed earlier.\n    copy.number.lls,\n\n    # Prior on each copy number state\n    # States are assumed to start at zero (no copies) and go up to K\n    # Here we put 90% prior on diploid state\n    prior = c( 0.02, 0.02, 0.9, 0.02, 0.02, 0.02 ),\n\n    # lambda = switch rate per bin\n    # Each bin is 1600bp, so 1/10 expects 1 switch every 16kb and so on\n    lambda = 1/20,\n\n    # site multipliers affect values across samples for each site\n    # these could be used to handle variation in coverage e.g. due to site-specific\n    # mapping, sequence data rates, GC content etc.\n    # Here we set these all to 1 for an initial run\n    site.multipliers = rep( 1, nrow( X ))\n)\n\nplot.copy.numbers( result$expected.copy.number, title = "Expected copy number (HMM model)" )\n')),(0,a.kt)("p",null,"Compare this with the previous plot based only on per-site coverage values for each sample - the new plot is much cleaner.  Also let's cluster samples again:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-R"},'o = hclust( # hierarchical clustering\n        dist( t(result$expected.copy.number) ) # of Euclidean distance matrix between samples\n)$order\nplot.copy.numbers( result$expected.copy.number[,o], title = "Expected copy number (HMM model, clustered)" )\n')),(0,a.kt)("h2",{id:"further-directions"},"Further directions"),(0,a.kt)("p",null,"Our model is getting better but there are lots of things we could do to improve this!"),(0,a.kt)("p",null,"First, there's variation between sites e.g. sequence coverage variation due to genome GC content or mapping performance.\nWe could try to control for this by iteravely fitting per-site multipliers in the above (maybe using MCMC or another algorithm)."),(0,a.kt)("p",null,"Second, having taken a first call of what the CNVs are, we now have more information to estimat ethe Gaussian parameters!  So we could go back and re-estimate, and iterate."),(0,a.kt)("p",null,"There are lots of other ways this model could be improved - challenge is to think of some."))}u.isMDXComponent=!0}}]);